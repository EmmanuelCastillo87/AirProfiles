{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before start we need to install two libs:\n",
    "- requests\n",
    "- beautifulsoup4\n",
    "\n",
    "This is made running the command: **pip install requests beautifulsoup4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The libs are imported\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as beautyS\n",
    "\n",
    "# We use a constant to store the URL of the website we want to scrape\n",
    "__URL__ = \"https://m-selig.ae.illinois.edu/ads/coord_seligFmt/\"\n",
    "\n",
    "# Now we request for the plain HTML of the website\n",
    "page = req.get(__URL__)\n",
    "\n",
    "# We need to parse the HTML code to handle the code\n",
    "soup = beautyS(page.text, 'html.parser')\n",
    "\n",
    "# Next we extract the name of the files present in the a elements of the HTML.\n",
    "# Note that we skip the first five links that correspond to the head of the table\n",
    "# and the parent directory.\n",
    "links = soup.table.find_all('a')[5:]\n",
    "\n",
    "# Here we get the name of the file, calculate teh absolute url, download the files\n",
    "# and put them in the \"data\" directory\n",
    "for link in links:\n",
    "    name = link.get('href')\n",
    "    url = __URL__ + name\n",
    "    name = 'data/' + name\n",
    "    res = req.get(url, allow_redirects=True)\n",
    "\n",
    "    open(name, 'wb').write(res.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
